import torch
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader
import importlib.util
import sys

# --- Import required variables from dnn.py ---
# Import dnn.py as a module to access X_tensor, Y_tensor, model, and N_ASSETS
spec = importlib.util.spec_from_file_location("dnn_module", "dnn.py")
dnn_module = importlib.util.module_from_spec(spec)
sys.modules["dnn_module"] = dnn_module
spec.loader.exec_module(dnn_module)

# Extract the variables we need from dnn.py
try:
    X_tensor = dnn_module.X_tensor
    Y_tensor = dnn_module.Y_tensor
    model = dnn_module.model
    N_ASSETS = dnn_module.N_ASSETS
except AttributeError as e:
    raise ValueError(f"Failed to import required variables from dnn.py. Error: {e}\n"
                     "Make sure dnn.py has been run successfully and all variables are defined:\n"
                     "- X_tensor\n"
                     "- Y_tensor\n"
                     "- model\n"
                     "- N_ASSETS")

# Validate the imported variables
if X_tensor is None or Y_tensor is None:
    raise ValueError("X_tensor or Y_tensor is None. Check dnn.py execution.")
if model is None:
    raise ValueError("model is None. Check dnn.py execution.")
if N_ASSETS is None or N_ASSETS <= 0:
    raise ValueError(f"N_ASSETS is invalid: {N_ASSETS}. Check dnn.py execution.")

print(f"\n--- Evaluation: Variables Imported Successfully ---")
print(f"X_tensor shape: {X_tensor.shape}")
print(f"Y_tensor shape: {Y_tensor.shape}")
print(f"Number of assets: {N_ASSETS}")

# --- 1. Split Data into Training and Testing Sets ---
# We use a time-series split (first 80% for training, last 20% for testing)
split_point = int(0.8 * len(X_tensor))

X_train, X_test = X_tensor[:split_point], X_tensor[split_point:]
Y_train, Y_test = Y_tensor[:split_point], Y_tensor[split_point:]

# We need the true realized returns for evaluation purposes
Y_true_test = Y_test.detach().numpy()

print(f"\n--- Step 4: Evaluation ---")
print(f"Test Samples: {len(X_test)}")

# --- 2. Generate Predictions on Test Set ---
model.eval() # Set model to evaluation mode
with torch.no_grad():
    # Predict the returns (mu_hat) for all days in the test set
    mu_hat_test_tensor = model(X_test)
    mu_hat_test = mu_hat_test_tensor.detach().numpy()

# --- 3. Optimization and Weight Calculation (Two-Stage Approach) ---

# We need a risk estimate (Sigma_hat). In the traditional two-stage model, 
# we often use a historical or rolling covariance.
# For simplicity and robustness, we use the historical covariance calculated from 
# the *entire* training period as a static risk estimate for all test days.

Y_train_np = Y_train.detach().numpy()
# Calculate the historical covariance matrix (Sigma_hat)
sigma_hat = np.cov(Y_train_np, rowvar=False) 
# rowvar=False means columns are variables (assets)

# Lists to store daily portfolio results
portfolio_weights = []
portfolio_returns = []

# Convert annual risk-free rate to daily for MSR optimization
risk_free_rate_annual = 0.05
risk_free_rate_daily = risk_free_rate_annual / 252.0

# Iterate over each day in the test set
for t in range(len(mu_hat_test)):
    mu_t = mu_hat_test[t]  # Predicted mean returns for day t+1
    
    # a. Define the Optimization Problem (Maximum Sharpe Ratio Portfolio)
    # Closed-form (no explicit leverage constraints):
    #   w* ∝ Σ^{-1} (μ_t - r_f_daily)
    # and then normalized so that sum(w*) = 1.
    try:
        Sigma_inv = np.linalg.inv(sigma_hat)
        # Excess returns over daily risk‑free rate
        excess_mu = mu_t - risk_free_rate_daily
        # Unnormalized MSR weights
        w_unnormalized = Sigma_inv @ excess_mu
        denom = np.sum(w_unnormalized)
        if np.abs(denom) < 1e-8:
            raise np.linalg.LinAlgError("Degenerate MSR solution (denominator ~ 0).")
        w_optimal = w_unnormalized / denom
    except np.linalg.LinAlgError:
        # Fallback to Equal Weights if matrix inversion fails or solution is degenerate
        w_optimal = np.ones(N_ASSETS) / N_ASSETS
    # Ensure weights sum to 1 (budget constraint)
    w_optimal = w_optimal / np.sum(w_optimal)
    
    # b. Evaluate the Portfolio Decision (using the *True* realized returns)
    r_true_t = Y_true_test[t]
    
    # Portfolio Return = w* @ r_true_t
    daily_return = np.dot(w_optimal, r_true_t)
    
    portfolio_weights.append(w_optimal)
    portfolio_returns.append(daily_return)

# --- 4. Final Evaluation Metrics ---

portfolio_returns = np.array(portfolio_returns)
annualized_returns = np.mean(portfolio_returns) * 252 # 252 trading days/year
annualized_volatility = np.std(portfolio_returns) * np.sqrt(252)

# Assuming a Risk-Free Rate (Rf) of 5% (0.05) for the Indian market
risk_free_rate = 0.05 
sharpe_ratio = (annualized_returns - risk_free_rate) / annualized_volatility

print("\n--- Two-Stage Portfolio Performance (Benchmark) ---")
print(f"Annualized Return: {annualized_returns * 100:.2f}%")
print(f"Annualized Volatility: {annualized_volatility * 100:.2f}%")
print(f"Sharpe Ratio (Rf=5%): {sharpe_ratio:.3f}")
print("-------------------------------------------------")
